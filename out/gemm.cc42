


#include "core/providers/cuda/math/gemm.h"
#include "core/providers/cpu/math/gemm_helper.h"
#include "core/providers/cuda/cuda_common.h"
#include "core/providers/cuda/shared_inc/fpgeneric.h"

namespace onnxruntime {
namespace cuda {

#define REGISTER_KERNEL_TYPED(T)                   ONNX_OPERATOR_VERSIONED_TYPED_KERNEL_EX(                Gemm, kOnnxDomain, 7, 8, T, kCudaExecutionProvider, (*KernelDefBuilder::Create())                     .TypeConstraint("T", DataTypeImpl::GetTensorType<T>()), Gemm<T>);                           ONNX_OPERATOR_VERSIONED_TYPED_KERNEL_EX(                Gemm, kOnnxDomain, 9, 10, T, kCudaExecutionProvider, (*KernelDefBuilder::Create())                     .TypeConstraint("T", DataTypeImpl::GetTensorType<T>()), Gemm<T>);                           ONNX_OPERATOR_VERSIONED_TYPED_KERNEL_EX(                Gemm, kOnnxDomain, 11, 12, T, kCudaExecutionProvider, (*KernelDefBuilder::Create())                     .TypeConstraint("T", DataTypeImpl::GetTensorType<T>()), Gemm<T>);                           ONNX_OPERATOR_TYPED_KERNEL_EX(                     Gemm, kOnnxDomain, 13, T, kCudaExecutionProvider, (*KernelDefBuilder::Create())                     .TypeConstraint("T", DataTypeImpl::GetTensorType<T>()), Gemm<T>);

REGISTER_KERNEL_TYPED(float)
REGISTER_KERNEL_TYPED(double)
REGISTER_KERNEL_TYPED(MLFloat16)
REGISTER_KERNEL_TYPED(BFloat16)

template <typename T>
Status Gemm<T>::ComputeInternal(OpKernelContext* ctx) const {
 typedef typename ToCudaType<T>::MappedType CudaT;

 const auto* X = ctx->Input<Tensor>(0);
 const auto* W = ctx->Input<Tensor>(1);
 const auto* B = ctx->Input<Tensor>(2);
 
 GemmHelper helper(X->Shape(), trans_A_, W->Shape(), trans_B_, B != nullptr ? B->Shape() : TensorShape({}));

 if (!helper.State().IsOK())
  return helper.State();

 int M = gsl::narrow_cast<int>(helper.M());
 int N = gsl::narrow_cast<int>(helper.N());
 int K = gsl::narrow_cast<int>(helper.K());
 auto* Y = ctx->Output(0, {M, N});
 CudaT* out_data = reinterpret_cast<CudaT*>(Y->MutableData<T>());

 CudaT one = ToCudaType<T>::FromFloat(1.0f);
 CudaT zero = ToCudaType<T>::FromFloat(0.0f);
 auto& device_prop = GetDeviceProp();

 
 if (beta_ != 0 && B != nullptr) {
  auto& b_shape = B->Shape();
  const CudaT* b_data = reinterpret_cast<const CudaT*>(B->Data<T>());
  if (b_shape.Size() == 1) {
   
   CUBLAS_RETURN_IF_ERROR(cublasCopyHelper(
     Stream(ctx), GetCublasHandle(ctx), M * N, b_data, 0, out_data, 1));
  } else if (b_shape.NumDimensions() == 1 || b_shape[0] == 1) {
   
   CUBLAS_RETURN_IF_ERROR(cublasGemmHelper(
     GetCublasHandle(ctx), CUBLAS_OP_N, CUBLAS_OP_N, N, M, 1, &one, b_data, N, GetConstOnes<CudaT>(M, Stream(ctx)), 1, &zero, out_data, N, device_prop));
  } else if (b_shape.NumDimensions() == 2 && b_shape[1] == 1) {
   
   CUBLAS_RETURN_IF_ERROR(cublasGemmHelper(
     GetCublasHandle(ctx), CUBLAS_OP_N, CUBLAS_OP_N, N, M, 1, &one, GetConstOnes<CudaT>(N, Stream(ctx)), N, b_data, 1, &zero, out_data, N, device_prop));
  } else {
   
   CUDA_RETURN_IF_ERROR(cudaMemcpyAsync(out_data, b_data, static_cast<size_t>(M) * N * sizeof(T), cudaMemcpyDeviceToDevice, Stream(ctx)));
  }
 }

 CudaT alpha = ToCudaType<T>::FromFloat(alpha_);
 CudaT beta = ToCudaType<T>::FromFloat(beta_);
 
 CUBLAS_RETURN_IF_ERROR(cublasGemmHelper(
   GetCublasHandle(ctx), trans_B_ ? CUBLAS_OP_T : CUBLAS_OP_N, trans_A_ ? CUBLAS_OP_T : CUBLAS_OP_N, N, M, K, &alpha, reinterpret_cast<const CudaT*>(W->Data<T>()), (trans_B_ ? K : N), reinterpret_cast<const CudaT*>(X->Data<T>()), (trans_A_ ? M : K), B != nullptr ? &beta : &zero, out_data, N, device_prop));

 return Status::OK();
}

} 
} 
